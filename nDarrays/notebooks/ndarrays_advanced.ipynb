{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "data_dir = '/data/tutorials/nDarrays'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multidimensional Arrays - Advanced Tutorial\n",
    "======\n",
    "\n",
    "# Outline\n",
    "\n",
    "(sample xarray extensions)\n",
    "\n",
    "1. EOF analysis on xarray objects ([`eofs`](http://ajdawson.github.io/eofs/index.html))\n",
    "1. Combining xarray objects with vector shapes ([`regionmask`](http://regionmask.readthedocs.io/en/stable/index.html))\n",
    "\n",
    "(xarray and big data)\n",
    "1. Challenge: Out of core computation with [dask](https://dask.pydata.org/en/latest/)\n",
    "2. Scaling out with [dask-distributed](http://distributed.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "from eofs.xarray import Eof\n",
    "\n",
    "import dask\n",
    "from multiprocessing.pool import ThreadPool\n",
    "dask.set_options(pool=ThreadPool(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF analysis using xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(os.path.join(data_dir, 'SST_global.nc'))\n",
    "ds.info()\n",
    "sst = ds['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resample to monthly\n",
    "sst_monthly = sst.resample('MS', dim='time', how='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate climatological anomalies\n",
    "climatology = sst_monthly.groupby('time.month').mean('time')\n",
    "anomalies = sst_monthly.groupby('time.month') - climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll subset the data to just the central/north Pacific\n",
    "enso_34_region = dict(latitude=slice(62.5, -22.5),\n",
    "                      longitude=slice(117.5, 262.5))\n",
    "enso_34_anoms = anomalies.sel(**enso_34_region)\n",
    "\n",
    "# we'll also select only the months between November and March\n",
    "def month_in_ndjfm(month):\n",
    "    if month >= 11 or month <= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "groups = xr.DataArray([month_in_ndjfm(t.month) for t in enso_34_anoms['time']],\n",
    "                      dims='time', coords={'time': enso_34_anoms['time']}, name='ndjfm')\n",
    "\n",
    "enso_34_anoms_ndjfm = enso_34_anoms.where(groups, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check, here's the first month in our dataarray\n",
    "enso_34_anoms_ndjfm.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the EOF analysis on the temperature anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "# latitude weights are applied before the computation of EOFs.\n",
    "coslat = np.cos(np.deg2rad(enso_34_anoms_ndjfm.coords['latitude'].values))\n",
    "wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "solver = Eof(enso_34_anoms_ndjfm, weights=wgts)\n",
    "\n",
    "# Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "# PC time series and the input SST anomalies at each grid point, and the\n",
    "# leading PC time series itself.\n",
    "eof1 = solver.eofsAsCorrelation(neofs=1)\n",
    "pc1 = solver.pcs(npcs=1, pcscaling=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the EOFs/PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the leading EOF expressed as correlation in the Pacific domain.\n",
    "clevs = np.linspace(-1, 1, 11)\n",
    "clevs = 11\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=215.25))\n",
    "fill = eof1.sel(mode=0).plot.contourf(\n",
    "    ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "    add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.LAND, facecolor='w', edgecolor='k')\n",
    "cb = plt.colorbar(fill, orientation='horizontal')\n",
    "cb.set_label('correlation coefficient', fontsize=12)\n",
    "ax.set_title('EOF1 expressed as correlation', fontsize=16)\n",
    "\n",
    "def plot_classic_enso(pc1):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = pc1.time.values\n",
    "    y = pc1[:, 0].values\n",
    "\n",
    "    ax.plot(x, y, color='k', linewidth=2)\n",
    "    ax.fill_between(x, y, 0, where=(y >= 0), color='r', interpolate=True)\n",
    "    ax.fill_between(x, y, 0, where=(y < 0), color='b', interpolate=True)\n",
    "\n",
    "    ax.axhline(0, color='k')\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel('Normalized Units')\n",
    "    ax.set_title('PC1 Time Series', fontsize=16)\n",
    "    \n",
    "    \n",
    "# Plot the leading PC time series.\n",
    "plot_classic_enso(pc1)\n",
    "\n",
    "# pc1[:, 0].plot(color='b', linewidth=2)\n",
    "# ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: \n",
    "\n",
    "We just looked at the first EOF/PC. Explore these results by tweaking the a) the number of PCs, b) the analysis region, c) the time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking using `regionmask`\n",
    "\n",
    "`regionmask` is a package that when combined with xarray allows for easy masking / selecting of spatial regions in gridded datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regionmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(os.path.join(data_dir, 'airtemp_global.nc'))\n",
    "KELVIN = 273.15\n",
    "t2m = ds['t2m'].resample('AS', dim='time', how='mean') - KELVIN\n",
    "\n",
    "masks  = regionmask.defined_regions.giorgi.mask(t2m,\n",
    "                                                lat_name='latitude',\n",
    "                                                lon_name='longitude',\n",
    "                                                wrap_lon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.plot(levels=masks.max(), cmap='tab20c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionmask.defined_regions.giorgi.abbrevs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get a mask-averaged timeseries for each of these masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(index=t2m.coords['time'])\n",
    "\n",
    "for key in regionmask.defined_regions.giorgi.abbrevs:\n",
    "    mask_num = regionmask.defined_regions.giorgi.map_keys(key)\n",
    "    df[key] = t2m.where(masks == mask_num).mean(\n",
    "        ('latitude', 'longitude')).to_series()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_slope(series):\n",
    "    from scipy.stats.mstats import theilslopes\n",
    "    x = series.index.year\n",
    "    y = series.values\n",
    "    \n",
    "    medslope, _, lo, up = theilslopes(y)\n",
    "    \n",
    "    return medslope\n",
    "\n",
    "df.apply(calc_slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - plot map of region slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Use dask to repeat this analysis \"out-of-core\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Distributed and Xarray\n",
    "\n",
    "[`Dask.distributed`](https://distributed.readthedocs.io/en/latest/) is a lightweight library for distributed computing in Python. It extends both the concurrent.futures and dask APIs to moderate sized clusters.\n",
    "\n",
    "xarray can use dask distributed in much the same way it uses dask. Here's a link to a wiki/screen-cast that describes how to use jupyter notebooks, dask distributed and xarray on a HPC environment.\n",
    "\n",
    "https://github.com/pangeo-data/pangeo-discussion/wiki/Getting-Started-with-Dask-on-Cheyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ndarrays)",
   "language": "python",
   "name": "ndarrays"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
